{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from nltk import pos_tag\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.temptalia.com/category/reviews/page/1'\n",
    "response = requests.get(url)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "links = soup.find_all(class_='btn btn-secondary btn-lg more-link')\n",
    "for link in links:\n",
    "    print(link.get('href'))\n",
    "url_list = (list(range(1,1790)))\n",
    "product_links = []\n",
    "for url_end in url_list:\n",
    "    url = ('https://www.temptalia.com/category/reviews/page/' + str(url_end))\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    links = soup.find_all(class_='btn btn-secondary btn-lg more-link')\n",
    "    for link in links:\n",
    "        product_links.append(link.get('href'))\n",
    "with open(\"output.csv\",\"w\") as outFile:\n",
    "    wr = csv.writer(outFile)\n",
    "    wr.writerows(product_links)\n",
    "    names = set()\n",
    "reviews = set()\n",
    "grades = []\n",
    "for link in product_links:\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    product_names = soup.find_all('figcaption')\n",
    "    product_reviews = (soup.find_all('p'))\n",
    "    product_grades = (soup.find_all(class_ = 'glossover-grade f-7 bold'))\n",
    "    for product in product_names:\n",
    "        if \"Look Details\" not in product.text:\n",
    "            current_prod = product.text\n",
    "            print(product.text)\n",
    "            names.add(product.text)\n",
    "            for review in product_reviews:\n",
    "                if current_prod in review.text:\n",
    "                    print(review.text)\n",
    "                    reviews.add(review.text)\n",
    "    for review in product_reviews:\n",
    "        if review.find(class_ = 'shadereview') != None:\n",
    "            print(review.text)\n",
    "            reviews.add(review.text)\n",
    "    for grade in product_grades:\n",
    "        print(grade.text)\n",
    "        grades.append(grade.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(names)\n",
    "reviews = list(reviews)\n",
    "df = pd.DataFrame(data = {'review_text': reviews, 'score': grades[:14767]})\n",
    "df.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['review_text'] = df['review_text'].str.replace('\\n', '')\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "products = []\n",
    "for i in range(len(df)):\n",
    "    product = re.findall('^(.*?)(\\s*\\sis|includes|consists|contains|are|has|include|pairs|was|comes|features|will|come|appears|make|blends)', df['review_text'].iloc[i])\n",
    "    if product != []:\n",
    "        products.append(product[0][0])\n",
    "    else:\n",
    "        products.append('unknown')\n",
    "df['product_name'] = products\n",
    "prices = []\n",
    "for i in range(len(df)):\n",
    "    price = re.search(r'\\((.*?)\\)',df['product_name'].iloc[i])\n",
    "    print (i)\n",
    "    if price != None:\n",
    "        prices.append(price.group(1))\n",
    "    else:\n",
    "        prices.append('unknown')\n",
    "df['prices'] = prices\n",
    "clean_names = []\n",
    "for i in range(len(df)):\n",
    "    name = df['product_name'].iloc[i].replace(f'({df.prices.iloc[i]})', '')\n",
    "    clean_names.append(name)\n",
    "df['clean_names'] = clean_names\n",
    "df.to_csv('output_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in cleaned data\n",
    "df = pd.read_csv('output_clean.csv')\n",
    "df = df.replace(np.nan, '', regex=True)\n",
    "df = df[['review_text', 'score', 'product_name', 'prices', 'clean_names']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=329618517)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_tokens(document):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(document)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = []\n",
    "for item in train['review_text'].values.astype('U'):\n",
    "    tokenized_reviews.append(return_tokens(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cats(dataframe, cats):\n",
    "    for cat in cats:\n",
    "        dataframe['type'][dataframe['review_text'].map(lambda x: x.lower()).str.contains(cat)] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nothing(tokens):\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Extracting and Labeling Product Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['type'] = ''\n",
    "types = ['lipstick','gloss','eyeshadow']\n",
    "extract_cats(train, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2454,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = train.loc[train['type'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2455,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label_train = labeled['review_text']\n",
    "y_label_train = labeled['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['eyeshadow', 'gloss', 'lipstick'], dtype=object)"
      ]
     },
     "execution_count": 2456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2457,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "label_train_vect = vectorizer.fit_transform(x_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 2458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.LinearSVC()\n",
    "clf.fit(label_train_vect, y_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988147646461226"
      ]
     },
     "execution_count": 2459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(label_train_vect, y_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2460,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train)):\n",
    "    train['type'].iloc[i] == ''\n",
    "    train['type'].iloc[i] = clf.predict(vectorizer.transform([train['review_text'].iloc[i]]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2461,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelan/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Retraining model/populate whole df\n",
    "Xtrain_vect = vectorizer.fit_transform(train['review_text'])\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(Xtrain_vect, train['type'])\n",
    "for i in range(len(df)):\n",
    "    df['type'].iloc[i] = clf.predict(vectorizer.transform([df['review_text'].iloc[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eyeshadow', 'gloss', 'lipstick'}"
      ]
     },
     "execution_count": 2462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in df['type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chelan/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['adjs'] = ''\n",
    "for i in range(len(df)):\n",
    "    df['adjs'].iloc[i] = [x[0] for x in pos_tag(return_tokens(df['review_text'].iloc[i])) if x[1] == 'JJ']                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Recommender Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_rec(text, data):\n",
    "    adjs = [x[0] for x in pos_tag(return_tokens(text)) if x[1] == 'JJ']\n",
    "    print(adjs)\n",
    "    count_vect = CountVectorizer(tokenizer=do_nothing,\n",
    "                             preprocessor=None,\n",
    "                             lowercase=False)\n",
    "    adj_vect = count_vect.fit_transform(data['review_text'])\n",
    "    NMF_count_data = NMF_count.fit_transform(adj_vect)\n",
    "    new_vec = NMF_count.transform(count_vect.transform(adjs))\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='cosine', algorithm='brute')\n",
    "    nn.fit(NMF_count_data)\n",
    "    results = nn.kneighbors(new_vec)\n",
    "    print(data['adjs'].iloc[results[1][0][0]])\n",
    "    return data.iloc[results[1][0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long-lasting']\n",
      "['various', 'greenish', 'navy', 'grassy']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "review_text     Wet ‘n’ Wild Earth Looks Small From Down Here ...\n",
       "score                                                        \\nB \n",
       "product_name    Wet ‘n’ Wild Earth Looks Small From Down Here ...\n",
       "prices                                                         -1\n",
       "clean_names     Wet ‘n’ Wild Earth Looks Small From Down Here ...\n",
       "type                                                  [eyeshadow]\n",
       "adjs                            [various, greenish, navy, grassy]\n",
       "price_substr    Wet ‘n’ Wild Earth Looks Small From Down Here ...\n",
       "price                                                        2.99\n",
       "Name: 12273, dtype: object"
      ]
     },
     "execution_count": 2466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_review = 'glittery eyeshadow, shiny, sparkles multicolored, long-lasting'\n",
    "data = df[(df['type']=='eyeshadow') & (df['price']< 25.00) & (df['price']> 0)]\n",
    "better_rec(sample_review, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Formatting for Output to Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2467,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.groupby('product_name').adjs.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2468,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_trimmed2 = df_new.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2469,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_trimmed['adjs'] = df['adjs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue Velvet</td>\n",
       "      <td>medium-dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue Velvet</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue Velvet</td>\n",
       "      <td>dusty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue Velvet</td>\n",
       "      <td>luminous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Velvet</td>\n",
       "      <td>finish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_name            0\n",
       "0  Blue Velvet  medium-dark\n",
       "1  Blue Velvet         soft\n",
       "2  Blue Velvet        dusty\n",
       "3  Blue Velvet     luminous\n",
       "4  Blue Velvet       finish"
      ]
     },
     "execution_count": 2470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_trimmed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2471,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_trimmed.to_csv('labeled_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2472,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame_trimmed2.to_csv('desc_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search('[0-9\\.]+', '$12.00 for 0.059 oz.').group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_substr'] = df['review_text'].map(lambda x: x[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price0 = []\n",
    "for i in df['price_substr']:\n",
    "    try:\n",
    "        if '.' != (re.search('[0-9\\.]+', i).group()) and '.' in (re.search('[0-9\\.]+', i).group()): \n",
    "            price0.append(re.search('[0-9\\.]+', i).group())\n",
    "        else:\n",
    "            price0.append(0)\n",
    "    except:\n",
    "        price0.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = price0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['product_name', 'price']].to_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades = df.groupby('score').adjs.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grades.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(vectorizer.transform(Xtrain), ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
